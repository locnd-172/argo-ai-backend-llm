{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "google_api_key = \"AIzaSyBkEMHu2H_9osfTFwGS3hN0KPy7a1s0gBY\"\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key)\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "print(len(vector))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pdfquery import PDFQuery\n",
    "\n",
    "pdf = PDFQuery('test2.pdf')\n",
    "# pdf = PDFQuery('test2.pdf')\n",
    "pdf.load()\n",
    "\n",
    "# Use CSS-like selectors to locate the elements\n",
    "text_elements = pdf.pq('LTTextLineHorizontal')\n",
    "\n",
    "# Extract the text from the elements\n",
    "text = [t.text for t in text_elements]\n",
    "for t in text:\n",
    "    print(t)\n",
    "\n",
    "paragraph = ' '.join(text)\n",
    "# print(\" \".join(text))"
   ],
   "id": "64355a85f98886af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def chunk_document(document):\n",
    "    document = document.split(\" \")\n",
    "    N = len(document)\n",
    "    step = 500\n",
    "    chunked_documents = []\n",
    "    for i in range(0, N, step):\n",
    "        chunked_document = ' '.join(document[i:i + step]).splitlines()\n",
    "        chunked_documents.append(chunked_document)\n",
    "\n",
    "    return chunked_documents\n",
    "\n",
    "\n",
    "def embed_document(document):\n",
    "    chunked_documents = chunk_document(document)\n",
    "    documents_embeddings = []\n",
    "    for document in chunked_documents:\n",
    "        document_embedding = embeddings.embed_query(document)\n",
    "        documents_embeddings.append(document_embedding)\n",
    "\n",
    "    return documents_embeddings\n",
    "\n",
    "\n",
    "document_embeddings = embed_document(paragraph)\n",
    "# documents = embed_document(paragraph)\n",
    "# print(chunked_documents)\n",
    "\n",
    "for embedding in document_embeddings:\n",
    "    print(embedding[:5])"
   ],
   "id": "d291e98a417ad3d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ],
   "id": "5ead39f04dc8677c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [],
   "id": "349c9df29b019fc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def pull_url(url):\n",
    "    page = requests.get(url)\n",
    "    if page.status_code == 200:\n",
    "        return page\n",
    "    else:\n",
    "        print(f'The url {url} returned a status of {page.status_code}')\n",
    "\n",
    "\n",
    "#2: Make some soup\n",
    "def make_soup(page):\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "url = 'https://www.jetbrains.com/help/pycharm/creating-virtual-environment.html'\n",
    "page = pull_url(url)\n",
    "soup = make_soup(page)\n",
    "# print(soup.prettify())\n",
    "\n",
    "from src.module.gemini.gemini_services import call_model_gemini\n",
    "from src.module.gemini.prompts import PROMPT_PREPROCESS_HTML\n",
    "\n",
    "formatted_prompt = PROMPT_PREPROCESS_HTML.format(\n",
    "    html_code=soup.prettify()\n",
    ")\n",
    "\n",
    "respond = call_model_gemini(formatted_prompt)\n",
    "print(respond)"
   ],
   "id": "e7d40f63026bf203",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from docx import Document\n",
    "\n",
    "\n",
    "def chunk_document(document):\n",
    "    document = document.split(\" \")\n",
    "    N = len(document)\n",
    "    step = 500\n",
    "    chunked_documents = []\n",
    "    for i in range(0, N, step):\n",
    "        chunked_document = ' '.join(' '.join(document[i:i + step]).splitlines())\n",
    "        chunked_documents.append(chunked_document)\n",
    "\n",
    "    return chunked_documents\n",
    "\n",
    "\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    fullText = []\n",
    "    for para in doc.paragraphs:\n",
    "        fullText.append(para.text)\n",
    "    return '\\n'.join(fullText)\n",
    "\n",
    "\n",
    "# print(read_docx('tmp.docx'))\n",
    "# print(chunk_document((read_docx('tmp.docx'))))\n",
    "print(chunk_document(respond['response']))\n",
    "\n",
    "print(len(chunk_document(respond['response'])))"
   ],
   "id": "f1237e8b4786e47f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "f8ff0243522f2c79"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
